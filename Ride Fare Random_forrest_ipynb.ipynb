{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ml Taxi Fiar -Report Random forrest. .ipynb.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwdBtEk75FXU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5e14e2cc-f3d6-4ac3-a35a-c51c74fdc5f3"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy import stats\n",
        "import warnings\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCOGdFlQ5R88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe = pd.read_csv(\"/content/drive/My Drive/ML Project Taxi Fair/train.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LR0HBWX5Vn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Aofbj5J6Ka_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save dataset without nan values\n",
        "dataframe.to_csv(\"/content/drive/My Drive/ML Project Taxi Fair/Train_without_nan.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj5HDciP5d7f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "3541d1f0-b698-4736-bea9-320ca6bbd06c"
      },
      "source": [
        "dataframe.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tripid                       0\n",
              "additional_fare              0\n",
              "duration                     0\n",
              "meter_waiting                0\n",
              "meter_waiting_fare           0\n",
              "meter_waiting_till_pickup    0\n",
              "pickup_time                  0\n",
              "drop_time                    0\n",
              "pick_lat                     0\n",
              "pick_lon                     0\n",
              "drop_lat                     0\n",
              "drop_lon                     0\n",
              "fare                         0\n",
              "label                        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwl2ul3G5fwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Try to fit the data without any transeformation\n",
        "\n",
        "#Convert labels for 1 and 0\n",
        "#Before do describe, Let's convert the label as 1 and 0 .(1-correct and 0-incorrect)\n",
        "def encoding_label(label):\n",
        "  if(label=='correct'):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "dataframe['label']= dataframe['label'].apply(encoding_label).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_cloBp66tYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzDx4dUS5yKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = dataframe.drop(columns=['label', 'tripid', 'drop_time', 'pickup_time']).values\n",
        "Y = dataframe['label'].values\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.20, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fESTCV9h6FjZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "cd639e7f-4ecc-48d4-fb61-01914d3437a9"
      },
      "source": [
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKUv7FgN7dvn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "238833ed-d4a0-4580-c902-6f7ece9dcdc6"
      },
      "source": [
        "print(\"Accuracy score : {0}\".format(model.score(X_validation, Y_validation)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score : 0.9398939304655274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCvU0m2s7oWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82548a16-8def-456e-c934-7ea8be510a59"
      },
      "source": [
        "predictions = model.predict(X_validation)\n",
        "\n",
        "print(\"F1 score {0}\".format(f1_score(predictions, Y_validation)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score 0.967741935483871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5fmSKCL8s1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#So the raw data without any tranformations gives 0.910 accuracy and 0.95059 f1 score\n",
        "#Let's transform the data by np.log because off high skewness\n",
        "\n",
        "dataframe_tr = dataframe.drop(columns=['tripid','tripid', 'drop_time', 'pickup_time'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHqybk_s9rFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For log scale the value can't be zero. So add 1 to every cell\n",
        "dataframe_tr = dataframe_tr+1\n",
        "\n",
        "#Convert to log scale\n",
        "dataframe_tr = np.log(dataframe_tr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95eJ73Ye98Tv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9f0e3dc8-f00c-4702-f023-79a5c1231030"
      },
      "source": [
        "#Model fit and train\n",
        "X = dataframe_tr.drop(columns=['label']).values\n",
        "Y = dataframe['label'].values\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.20, random_state=1)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "predictions = model.predict(X_validation)\n",
        "print(\"Accuracy score : {0}\".format(model.score(X_validation, Y_validation)))\n",
        "print(\"F1 score {0}\".format(f1_score(predictions, Y_validation)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score : 0.9398939304655274\n",
            "F1 score 0.9677215189873418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noPqujOO9-c8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7e3325c1-6b68-4541-a025-484ad2e401a3"
      },
      "source": [
        "#Lets deal with np.log and min max scaler\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(dataframe_tr.drop(columns=['label']).values)\n",
        "\n",
        "#Transform and svae to X\n",
        "X = scaler.transform(dataframe_tr.drop(columns=['label']).values)\n",
        "Y = dataframe['label'].values\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.20, random_state=1)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "predictions = model.predict(X_validation)\n",
        "print(\"Accuracy score : {0}\".format(model.score(X_validation, Y_validation)))\n",
        "print(\"F1 score {0}\".format(f1_score(predictions, Y_validation)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score : 0.9390100176782558\n",
            "F1 score 0.9672416521601519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJPPbq0A_sRx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a80b6e06-1b34-4a06-8c76-b7fe0bdba87b"
      },
      "source": [
        "#Lets deal with np.log and Standard scaler\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(dataframe_tr.drop(columns=['label']).values)\n",
        "\n",
        "#Transform and svae to X\n",
        "X = scaler.transform(dataframe_tr.drop(columns=['label']).values)\n",
        "Y = dataframe['label'].values\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.20, random_state=1)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "predictions = model.predict(X_validation)\n",
        "print(\"Accuracy score : {0}\".format(model.score(X_validation, Y_validation)))\n",
        "print(\"F1 score {0}\".format(f1_score(predictions, Y_validation)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score : 0.939304655274013\n",
            "F1 score 0.967394745172523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuqrnPSyAAos",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "05fe298b-a0e3-4b93-b6ec-28581e434b54"
      },
      "source": [
        "#Lets deal with np.log and Robust scaler\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "scaler = RobustScaler()\n",
        "scaler.fit(dataframe_tr.drop(columns=['label']).values)\n",
        "\n",
        "#Transform and svae to X\n",
        "X = scaler.transform(dataframe_tr.drop(columns=['label']).values)\n",
        "Y = dataframe['label'].values\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.20, random_state=1)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "predictions = model.predict(X_validation)\n",
        "print(\"Accuracy score : {0}\".format(model.score(X_validation, Y_validation)))\n",
        "print(\"F1 score {0}\".format(f1_score(predictions, Y_validation)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score : 0.939304655274013\n",
            "F1 score 0.9674050632911393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUrPCMomAJKe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "fd3e2785-2c8b-4fac-e33f-16984f689293"
      },
      "source": [
        "#Lets choose np.log and minmax and Grid search for parameters\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "parameters = {\n",
        "     'criterion' : ['gini', 'entropy'],\n",
        "    'max_depth' : [18,20,25],\n",
        "    'max_features' : ['auto','sqrt','log2']\n",
        "    }\n",
        "####Minmaxand log transformation start\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(dataframe_tr.drop(columns=['label']).values)\n",
        "\n",
        "#Transform and svae to X\n",
        "X = scaler.transform(dataframe_tr.drop(columns=['label']).values)\n",
        "Y = dataframe['label'].values\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.20, random_state=1)\n",
        "\n",
        "####end of transformation\n",
        "\n",
        "model = RandomForestClassifier(verbose=0, n_jobs=5)\n",
        "\n",
        "clf = GridSearchCV(model, parameters)\n",
        "\n",
        "# Fit the grid search\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "# View The Best Parameters\n",
        "print('Best Criterion:', clf.best_estimator_.get_params()['criterion'])\n",
        "#print('Best n_estimators:', clf.best_estimator_.get_params()['n_estimators']) #max_depth\n",
        "print('Best max_features:', clf.best_estimator_.get_params()['max_features'])\n",
        "print(\"Best score : \", clf.best_score_)\n",
        "\n",
        "#Predictions\n",
        "model = clf.best_estimator_\n",
        "predictions = model.predict(X_validation)\n",
        "print(\"F1 Score : \", f1_score(Y_validation, predictions))\n",
        "clf.best_estimator_\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Criterion: entropy\n",
            "Best max_features: auto\n",
            "Best score :  0.9435681026421895\n",
            "F1 Score :  0.9680480860487188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='entropy', max_depth=25, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=5,\n",
              "                       oob_score=False, random_state=None, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab0YdJicBnIW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c079a9c5-e364-4042-b38f-540b28d3b67d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy0FHN97Q3a8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MI Taxi fair -Report Ensemble Bagging  ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwdBtEk75FXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy import stats\n",
        "import warnings\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "from sklearn import datasets\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "import itertools\n",
        "from mlxtend.plotting import plot_learning_curves\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LdsOt_5Olwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCOGdFlQ5R88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe = pd.read_csv(\"/content/drive/My Drive/ML Project Taxi Fair/train.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LR0HBWX5Vn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Aofbj5J6Ka_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save dataset without nan values\n",
        "dataframe.to_csv(\"/content/drive/My Drive/ML Project Taxi Fair/Train_without_nan.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj5HDciP5d7f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "f29dc0f1-dce9-4c9b-f809-544ada815745"
      },
      "source": [
        "dataframe.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tripid                       0\n",
              "additional_fare              0\n",
              "duration                     0\n",
              "meter_waiting                0\n",
              "meter_waiting_fare           0\n",
              "meter_waiting_till_pickup    0\n",
              "pickup_time                  0\n",
              "drop_time                    0\n",
              "pick_lat                     0\n",
              "pick_lon                     0\n",
              "drop_lat                     0\n",
              "drop_lon                     0\n",
              "fare                         0\n",
              "label                        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwl2ul3G5fwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Try to fit the data without any transeformation\n",
        "\n",
        "#Convert labels for 1 and 0\n",
        "#Before do describe, Let's convert the label as 1 and 0 .(1-correct and 0-incorrect)\n",
        "def encoding_label(label):\n",
        "  if(label=='correct'):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "dataframe['label']= dataframe['label'].apply(encoding_label).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_cloBp66tYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzDx4dUS5yKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = dataframe.drop(columns=['label', 'tripid', 'drop_time', 'pickup_time']).values\n",
        "Y = dataframe['label'].values\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.20, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fESTCV9h6FjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf1 = DecisionTreeClassifier(criterion='entropy', max_depth=1)\n",
        "clf2 = KNeighborsClassifier(n_neighbors=1)    \n",
        "\n",
        "bagging1 = BaggingClassifier(base_estimator=clf1, n_estimators=10, max_samples=0.8, max_features=0.8)\n",
        "bagging2 = BaggingClassifier(base_estimator=clf2, n_estimators=10, max_samples=0.8, max_features=0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID7RbWFRO3j7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "e0199ac4-9e23-4766-feae-8eb2de8320e5"
      },
      "source": [
        "label = ['Decision Tree', 'K-NN', 'Bagging Tree', 'Bagging K-NN']\n",
        "clf_list = [clf1, clf2, bagging1, bagging2]\n",
        "\n",
        "\n",
        "grid = itertools.product([0,1],repeat=2)\n",
        "\n",
        "for clf, label_, grd in zip(clf_list, label, grid):        \n",
        "    scores = cross_val_score(clf, X_train, Y_train, cv=3, scoring='f1')\n",
        "    print(\"%s F1 Socre: %.6f (+/- %.4f) \" %(label_, scores.mean(), scores.std()))\n",
        "    clf.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision Tree F1 Socre: 0.952704 (+/- 0.0001) \n",
            "K-NN F1 Socre: 0.959509 (+/- 0.0010) \n",
            "Bagging Tree F1 Socre: 0.952704 (+/- 0.0001) \n",
            "Bagging K-NN F1 Socre: 0.962183 (+/- 0.0027) \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKUv7FgN7dvn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "526fbd4d-a0f7-4a84-8d3a-eb095ba1ea3f"
      },
      "source": [
        "for clf, label_ in zip(clf_list, label):     \n",
        "  print(\"{0}  Accuracy score : {1}\".format(label_, clf.score(X_validation, Y_validation)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision Tree  Accuracy score : 0.9116087212728344\n",
            "K-NN  Accuracy score : 0.9242781378903948\n",
            "Bagging Tree  Accuracy score : 0.9116087212728344\n",
            "Bagging K-NN  Accuracy score : 0.9322333529758398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCvU0m2s7oWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "9ff1b6a4-6ebd-4502-8337-8656b93dbd83"
      },
      "source": [
        "for clf, label_ in zip(clf_list, label): \n",
        "  predictions = clf.predict(X_validation)\n",
        "  print(\"{0}  F1 score {1}\".format(label_, f1_score(predictions, Y_validation)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision Tree  F1 score 0.9537607891491985\n",
            "K-NN  F1 score 0.9587148594377509\n",
            "Bagging Tree  F1 score 0.9537607891491985\n",
            "Bagging K-NN  F1 score 0.9634107540566338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5fmSKCL8s1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#So the raw data without any tranformations gives 0.910 accuracy and 0.95059 f1 score\n",
        "#Let's transform the data by np.log because off high skewness\n",
        "\n",
        "dataframe_tr = dataframe.drop(columns=['tripid','tripid', 'drop_time', 'pickup_time'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHqybk_s9rFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For log scale the value can't be zero. So add 1 to every cell\n",
        "dataframe_tr = dataframe_tr+1\n",
        "\n",
        "#Convert to log scale\n",
        "dataframe_tr = np.log(dataframe_tr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95eJ73Ye98Tv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "e0eee6d3-7691-4c58-a93e-35fc59b3d478"
      },
      "source": [
        "#Model fit and train\n",
        "X = dataframe_tr.drop(columns=['label']).values\n",
        "Y = dataframe['label'].values\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.20, random_state=1)\n",
        "\n",
        "clf1 = DecisionTreeClassifier(criterion='entropy', max_depth=1)\n",
        "clf2 = KNeighborsClassifier(n_neighbors=1)    \n",
        "\n",
        "bagging1 = BaggingClassifier(base_estimator=clf1, n_estimators=10, max_samples=0.8, max_features=0.8)\n",
        "bagging2 = BaggingClassifier(base_estimator=clf2, n_estimators=10, max_samples=0.8, max_features=0.8)\n",
        "\n",
        "label = ['Decision Tree', 'K-NN', 'Bagging Tree', 'Bagging K-NN']\n",
        "clf_list = [clf1, clf2, bagging1, bagging2]\n",
        "\n",
        "\n",
        "grid = itertools.product([0,1],repeat=2)\n",
        "\n",
        "for clf, label_, grd in zip(clf_list, label, grid):        \n",
        "    scores = cross_val_score(clf, X_train, Y_train, cv=3, scoring='f1')\n",
        "    print(\"%s F1 Socre: %.6f (+/- %.4f) \" %(label_, scores.mean(), scores.std()))\n",
        "    clf.fit(X_train, Y_train)\n",
        "\n",
        "for clf, label_ in zip(clf_list, label): \n",
        "  predictions = clf.predict(X_validation)\n",
        "  print(\"{0}  : Accuracy score : {1}\".format(label_, clf.score(X_validation, Y_validation)))\n",
        "  print(\"{0}  : F1 score {1}\".format(label_, f1_score(predictions, Y_validation)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision Tree F1 Socre: 0.952704 (+/- 0.0001) \n",
            "K-NN F1 Socre: 0.955976 (+/- 0.0018) \n",
            "Bagging Tree F1 Socre: 0.952704 (+/- 0.0001) \n",
            "Bagging K-NN F1 Socre: 0.960120 (+/- 0.0050) \n",
            "Decision Tree  : Accuracy score : 0.9116087212728344\n",
            "Decision Tree  : F1 score 0.9537607891491985\n",
            "K-NN  : Accuracy score : 0.9163229228049499\n",
            "K-NN  : F1 score 0.954516335682255\n",
            "Bagging Tree  : Accuracy score : 0.9116087212728344\n",
            "Bagging Tree  : F1 score 0.9537607891491985\n",
            "Bagging K-NN  : Accuracy score : 0.9316440777843252\n",
            "Bagging K-NN  : F1 score 0.9631277813095994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noPqujOO9-c8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "9453e55d-39b8-4fde-ad01-43b2d1b6b3c8"
      },
      "source": [
        "#Lets deal with np.log and min max scaler\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(dataframe_tr.drop(columns=['label']).values)\n",
        "\n",
        "#Transform and svae to X\n",
        "X = scaler.transform(dataframe_tr.drop(columns=['label']).values)\n",
        "Y = dataframe['label'].values\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.20, random_state=1)\n",
        "\n",
        "clf1 = DecisionTreeClassifier(criterion='entropy', max_depth=1)\n",
        "clf2 = KNeighborsClassifier(n_neighbors=1)    \n",
        "\n",
        "bagging1 = BaggingClassifier(base_estimator=clf1, n_estimators=10, max_samples=0.8, max_features=0.8)\n",
        "bagging2 = BaggingClassifier(base_estimator=clf2, n_estimators=10, max_samples=0.8, max_features=0.8)\n",
        "\n",
        "label = ['Decision Tree', 'K-NN', 'Bagging Tree', 'Bagging K-NN']\n",
        "clf_list = [clf1, clf2, bagging1, bagging2]\n",
        "\n",
        "\n",
        "grid = itertools.product([0,1],repeat=2)\n",
        "\n",
        "for clf, label_, grd in zip(clf_list, label, grid):        \n",
        "    scores = cross_val_score(clf, X_train, Y_train, cv=3, scoring='f1')\n",
        "    print(\"%s F1 Socre: %.6f (+/- %.4f) \" %(label_, scores.mean(), scores.std()))\n",
        "    clf.fit(X_train, Y_train)\n",
        "\n",
        "for clf, label_ in zip(clf_list, label): \n",
        "  predictions = clf.predict(X_validation)\n",
        "  print(\"{0}  : Accuracy score : {1}\".format(label_, clf.score(X_validation, Y_validation)))\n",
        "  print(\"{0}  : F1 score {1}\".format(label_, f1_score(predictions, Y_validation)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision Tree F1 Socre: 0.952704 (+/- 0.0001) \n",
            "K-NN F1 Socre: 0.950749 (+/- 0.0005) \n",
            "Bagging Tree F1 Socre: 0.952704 (+/- 0.0001) \n",
            "Bagging K-NN F1 Socre: 0.959857 (+/- 0.0021) \n",
            "Decision Tree  : Accuracy score : 0.9116087212728344\n",
            "Decision Tree  : F1 score 0.9537607891491985\n",
            "K-NN  : Accuracy score : 0.9092516205067767\n",
            "K-NN  : F1 score 0.9506410256410256\n",
            "Bagging Tree  : Accuracy score : 0.9116087212728344\n",
            "Bagging Tree  : F1 score 0.9537607891491985\n",
            "Bagging K-NN  : Accuracy score : 0.9301708898055392\n",
            "Bagging K-NN  : F1 score 0.9624940655166957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJPPbq0A_sRx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "82ba75d2-8392-4656-d957-e72dca7479b6"
      },
      "source": [
        "#Lets deal with np.log and Standard scaler\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(dataframe_tr.drop(columns=['label']).values)\n",
        "\n",
        "#Transform and svae to X\n",
        "X = scaler.transform(dataframe_tr.drop(columns=['label']).values)\n",
        "Y = dataframe['label'].values\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.20, random_state=1)\n",
        "\n",
        "clf1 = DecisionTreeClassifier(criterion='entropy', max_depth=1)\n",
        "clf2 = KNeighborsClassifier(n_neighbors=1)    \n",
        "\n",
        "bagging1 = BaggingClassifier(base_estimator=clf1, n_estimators=10, max_samples=0.8, max_features=0.8)\n",
        "bagging2 = BaggingClassifier(base_estimator=clf2, n_estimators=10, max_samples=0.8, max_features=0.8)\n",
        "\n",
        "label = ['Decision Tree', 'K-NN', 'Bagging Tree', 'Bagging K-NN']\n",
        "clf_list = [clf1, clf2, bagging1, bagging2]\n",
        "\n",
        "\n",
        "grid = itertools.product([0,1],repeat=2)\n",
        "\n",
        "for clf, label_, grd in zip(clf_list, label, grid):        \n",
        "    scores = cross_val_score(clf, X_train, Y_train, cv=3, scoring='f1')\n",
        "    print(\"%s F1 Socre: %.6f (+/- %.4f) \" %(label_, scores.mean(), scores.std()))\n",
        "    clf.fit(X_train, Y_train)\n",
        "\n",
        "for clf, label_ in zip(clf_list, label): \n",
        "  predictions = clf.predict(X_validation)\n",
        "  print(\"{0}  : Accuracy score : {1}\".format(label_, clf.score(X_validation, Y_validation)))\n",
        "  print(\"{0}  : F1 score {1}\".format(label_, f1_score(predictions, Y_validation)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision Tree F1 Socre: 0.952704 (+/- 0.0001) \n",
            "K-NN F1 Socre: 0.955713 (+/- 0.0001) \n",
            "Bagging Tree F1 Socre: 0.952704 (+/- 0.0001) \n",
            "Bagging K-NN F1 Socre: 0.961652 (+/- 0.0019) \n",
            "Decision Tree  : Accuracy score : 0.9116087212728344\n",
            "Decision Tree  : F1 score 0.9537607891491985\n",
            "K-NN  : Accuracy score : 0.913671184443135\n",
            "K-NN  : F1 score 0.952961952159255\n",
            "Bagging Tree  : Accuracy score : 0.9116087212728344\n",
            "Bagging Tree  : F1 score 0.9537607891491985\n",
            "Bagging K-NN  : Accuracy score : 0.9301708898055392\n",
            "Bagging K-NN  : F1 score 0.9625414888572783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuqrnPSyAAos",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 912
        },
        "outputId": "f775af53-a142-494e-be8b-edefe4b90b34"
      },
      "source": [
        "#Lets deal with np.log and Robust scaler\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "scaler = RobustScaler()\n",
        "scaler.fit(dataframe_tr.drop(columns=['label']).values)\n",
        "\n",
        "#Transform and svae to X\n",
        "X = scaler.transform(dataframe_tr.drop(columns=['label']).values)\n",
        "Y = dataframe['label'].values\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.20, random_state=1)\n",
        "\n",
        "clf1 = DecisionTreeClassifier(criterion='entropy', max_depth=10)\n",
        "clf2 = KNeighborsClassifier(n_neighbors=1)    \n",
        "\n",
        "bagging1 = BaggingClassifier(base_estimator=clf1, n_estimators=20, max_samples=0.8, max_features=0.8)\n",
        "bagging2 = BaggingClassifier(base_estimator=clf2, n_estimators=20, max_samples=0.8, max_features=0.8)\n",
        "\n",
        "label = ['Decision Tree', 'K-NN', 'Bagging Tree', 'Bagging K-NN']\n",
        "clf_list = [clf1, clf2, bagging1, bagging2]\n",
        "\n",
        "\n",
        "grid = itertools.product([0,1],repeat=2)\n",
        "\n",
        "for clf, label_, grd in zip(clf_list, label, grid):        \n",
        "    scores = cross_val_score(clf, X_train, Y_train, cv=3, scoring='f1')\n",
        "    print(\"%s F1 Socre: %.6f (+/- %.4f) \" %(label_, scores.mean(), scores.std()))\n",
        "    clf.fit(X_train, Y_train)\n",
        "\n",
        "print(\"\\n\\n\\n\")\n",
        "for clf, label_ in zip(clf_list, label): \n",
        "  predictions = clf.predict(X_validation)\n",
        "  print(\"{0}  : Accuracy score : {1}\".format(label_, clf.score(X_validation, Y_validation)))\n",
        "  print(\"{0}  : F1 score {1}\".format(label_, f1_score(predictions, Y_validation)))\n",
        "\n",
        "#Ensemble Size\n",
        "num_est = map(int, np.linspace(1,100,20))\n",
        "bg_clf_cv_mean = []\n",
        "bg_clf_cv_std = []\n",
        "for n_est in num_est:    \n",
        "    bg_clf = BaggingClassifier(base_estimator=clf1, n_estimators=n_est, max_samples=0.8, max_features=0.8)\n",
        "    scores = cross_val_score(bg_clf, X, Y, cv=3, scoring='accuracy')\n",
        "    bg_clf_cv_mean.append(scores.mean())\n",
        "    bg_clf_cv_std.append(scores.std())\n",
        "\n",
        "plt.figure()\n",
        "(_, caps, _) = plt.errorbar(num_est, bg_clf_cv_mean, yerr=bg_clf_cv_std, c='blue', fmt='-o', capsize=5)\n",
        "for cap in caps:\n",
        "    cap.set_markeredgewidth(1)                                                                                                                                \n",
        "plt.ylabel('Accuracy'); plt.xlabel('Ensemble Size'); plt.title('Bagging Tree Ensemble');\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision Tree F1 Socre: 0.964184 (+/- 0.0016) \n",
            "K-NN F1 Socre: 0.954047 (+/- 0.0009) \n",
            "Bagging Tree F1 Socre: 0.965611 (+/- 0.0008) \n",
            "Bagging K-NN F1 Socre: 0.962358 (+/- 0.0007) \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Decision Tree  : Accuracy score : 0.9289923394225104\n",
            "Decision Tree  : F1 score 0.9617521028408188\n",
            "K-NN  : Accuracy score : 0.9160282852091927\n",
            "K-NN  : F1 score 0.954509177972865\n",
            "Bagging Tree  : Accuracy score : 0.9363582793164408\n",
            "Bagging Tree  : F1 score 0.9658767772511849\n",
            "Bagging K-NN  : Accuracy score : 0.9316440777843252\n",
            "Bagging K-NN  : F1 score 0.9634184799747713\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-ade042fa3296>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg_clf_cv_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbg_clf_cv_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'-o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcap\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcaps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_markeredgewidth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36merrorbar\u001b[0;34m(x, y, yerr, xerr, fmt, ecolor, elinewidth, capsize, barsabove, lolims, uplims, xlolims, xuplims, errorevery, capthick, data, **kwargs)\u001b[0m\n\u001b[1;32m   2527\u001b[0m         \u001b[0mlolims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlolims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muplims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muplims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlolims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxlolims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2528\u001b[0m         \u001b[0mxuplims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxuplims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrorevery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrorevery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapthick\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcapthick\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2529\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36merrorbar\u001b[0;34m(self, x, y, yerr, xerr, fmt, ecolor, elinewidth, capsize, barsabove, lolims, uplims, xlolims, xuplims, errorevery, capthick, **kwargs)\u001b[0m\n\u001b[1;32m   3167\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"errorevery's starting index must be an integer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3169\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_unit_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mydata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3171\u001b[0m         \u001b[0mplot_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_process_unit_info\u001b[0;34m(self, xdata, ydata, kwargs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2073\u001b[0;31m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_single_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'xunits'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_single_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mydata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yunits'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_process_single_axis\u001b[0;34m(data, axis, unit_name, kwargs)\u001b[0m\n\u001b[1;32m   2054\u001b[0m                 \u001b[0;31m# We only need to update if there is nothing set yet.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhave_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m                     \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m             \u001b[0;31m# Check for units in the kwargs, and if present update axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mupdate_units\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mregistered\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0munit\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m         \"\"\"\n\u001b[0;32m-> 1510\u001b[0;31m         \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmunits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1511\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/units.py\u001b[0m in \u001b[0;36mget_converter\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# If cache lookup fails, look up based on first element...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_first_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36msafe_first_element\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1648\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m         raise RuntimeError(\"matplotlib does not support generators \"\n\u001b[0m\u001b[1;32m   1651\u001b[0m                            \"as input\")\n\u001b[1;32m   1652\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: matplotlib does not support generators as input"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUrPCMomAJKe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "8e87f983-0fbd-4f5c-eaef-31c6eba1845c"
      },
      "source": [
        "#Lets choose np.log and minmax and Grid search for parameters\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "criterion = ['gini', 'entropy']\n",
        "max_depth = [4,6,8,12,16,20,24,28]\n",
        "splitter = ['best', 'random']\n",
        "parameters = dict(criterion=criterion, max_depth=max_depth, splitter=splitter)\n",
        "####Minmaxand log transformation start\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(dataframe_tr.drop(columns=['label']).values)\n",
        "\n",
        "#Transform and svae to X\n",
        "X = scaler.transform(dataframe_tr.drop(columns=['label']).values)\n",
        "Y = dataframe['label'].values\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.20, random_state=1)\n",
        "\n",
        "####end of transformation\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "clf = GridSearchCV(model, parameters)\n",
        "\n",
        "# Fit the grid search\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "# View The Best Parameters\n",
        "print('Best Criterion:', clf.best_estimator_.get_params()['criterion'])\n",
        "print('Best max_depth:', clf.best_estimator_.get_params()['max_depth'])\n",
        "print(\"Best score : \", clf.best_score_)\n",
        "\n",
        "#Predictions\n",
        "model = clf.best_estimator_\n",
        "predictions = model.predict(X_validation)\n",
        "print(\"F1 Score : \", f1_score(Y_validation, predictions))\n",
        "clf.best_estimator_\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Criterion: gini\n",
            "Best max_depth: 8\n",
            "Best score :  0.9359804628072703\n",
            "F1 Score :  0.9619530754597335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=8, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab0YdJicBnIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}